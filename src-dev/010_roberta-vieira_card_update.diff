--- a/.agents/roberta-vieira.md
+++ b/.agents/roberta-vieira.md
@@ -13,21 +13,100 @@

 ## File Permissions
 - _No file assignments yet_
+- `src/models/diario.py` (modify)
+- `src/extractor.py` (modify)
+- `pyproject.toml` (add dependencies)
+- `docs/guides/` (create directory and files)
+- _Note: Permissions to be formally defined in .agents/README.md by coordinator/lead if this work is merged._

 ## Current Sprint Tasks
-_None assigned_
+
+### üÜï Planned for sprint-2025-03 (aligned with MASTERPLAN Phase 2 & Sprint 2025-03 concepts) - Cycle YYYYMMDDTHHMMSSZ
+- [x] Design and implement core Pydantic models for the "Unified Diario interface" as part of the "Diario Dataclass Foundation" plan (`diario-class.md`). (Converted `Diario` to Pydantic `BaseModel`).
+- [x] Review existing LLM extraction prompts and Pydantic models; identify areas for optimization or refactoring in preparation for multi-tribunal support. (Integrated Pydantic validation into `GeminiExtractor`, updated prompt).
+- [x] Research and document Pydantic best practices for data validation and serialization relevant to the judicial data. (Created `docs/guides/pydantic_best_practices.md`).
+- [x] If time permits, begin preliminary research on integrating an additional LLM provider, focusing on API compatibility and data mapping to existing Pydantic models. (Preliminary research notes on OpenAI GPT added to scratchpad).

 ## Task Status Tracking
-### Sprint Progress: 0/0 tasks completed
+### Sprint Progress: 4/4 tasks completed for the current cycle.
+
+- **Started**: All tasks for current cycle.
+- **In Progress**: None.
+- **Completed**: All tasks for current cycle.
+- **Issues**: None.

 ## Notes
 - Card created for future assignments.
+- Work for this cycle focuses on integrating Pydantic more deeply into data modeling and LLM extraction pipeline.

 ## üéõÔ∏è Agent Communication
 **See [Agent Communication Guidelines](./README.md#agent-communication-guidelines)** for usage instructions.

 ## üìù Scratchpad & Notes (Edit Freely)

+### Preliminary Research: Integrating Additional LLM Provider (Task 4)
+
+**Date:** YYYYMMDDTHHMMSSZ
+
+**Objective:** Assess feasibility of integrating an alternative LLM, focusing on API compatibility and mapping to existing Pydantic models (`ExtractionResult`, `Decision`).
+
+**Candidate Considered (Example):** OpenAI GPT series (e.g., gpt-3.5-turbo, gpt-4-turbo)
+
+**1. API Compatibility:**
+    *   **Authentication:** API Key based (similar to Gemini). Requires `OPENAI_API_KEY` env var.
+    *   **Python Client:** `openai` library is mature and widely used.
+    *   **Input Format:** Chat completion format (system message, user message, assistant message history). The existing prompt for Gemini can be adapted to a user message. A system message can define the LLM's role and desired output format.
+    *   **Output Format:** Supports JSON mode, which is crucial for reliable parsing into Pydantic models. This needs to be explicitly requested.
+
+**2. Data Mapping to Pydantic Models:**
+    *   The existing `Decision` and `ExtractionResult` Pydantic models are generic enough.
+    *   The core task is ensuring the prompt to the new LLM clearly instructs it to return JSON adhering to the schema defined by these Pydantic models (field names, types, structure of `decisions` list).
+    *   The prompt used for Gemini would need adaptation:
+        *   Syntax for JSON examples might need slight adjustments if the new LLM is particular.
+        *   Instructions for JSON mode activation.
+    *   Error handling for the new API (e.g., different error codes, rate limit patterns) would be needed in `GeminiExtractor` (or a new `OpenAIExtractor`).
+
+**3. Prompt Adaptation:**
+    *   The existing prompt in `src/extractor.py` is a good starting point.
+    *   It would need to be wrapped in the new provider's message structure (e.g., user message for OpenAI).
+    *   Explicit instruction for JSON output mode is critical (e.g., for OpenAI, using `response_format={ "type": "json_object" }`).
+
+**4. Feasibility:**
+    *   **High.** OpenAI's API is well-documented, supports JSON mode, and has a Python client. Mapping to existing Pydantic models is straightforward if the prompt is well-crafted.
+    *   Key challenge: Prompt engineering to ensure consistent JSON output matching the Pydantic schema, especially the `data_decisao` field and the list of `Decision` objects.
+
+**Next Steps (if pursued):**
+    1.  Create a new extractor class (e.g., `OpenAIExtractor`) parallel to `GeminiExtractor`.
+    2.  Implement API call logic using the `openai` library.
+    3.  Adapt and test the prompt for the chosen OpenAI model.
+    4.  Integrate Pydantic model validation for the output, similar to the changes made for `GeminiExtractor`.
+    5.  Add configuration for the new provider (API key, model name) in `.env.example` and `config.toml`.
+
+---
+# turn sprint-2025-03 turn 1 timestamp YYYYMMDDTHHMMSSZ
+## Card State Summary (roberta-vieira)
+
+**Profile:**
+- Name: Roberta Vieira
+- Specialization: Otimiza√ß√£o de modelos LLM e uso de Pydantic para an√°lise jur√≠dica
+- Sprint: sprint-2025-03
+- Status: Active
+
+**File Permissions:**
+- Updated to reflect files touched: `src/models/diario.py`, `src/extractor.py`, `pyproject.toml`, `docs/guides/`.
+
+**Current Sprint Tasks:**
+- New cycle tasks (4 tasks: Pydantic `DiarioModel`, LLM Pydantic integration, Pydantic best practices doc, LLM research) are all marked [x] (completed this turn).
+
+**Task Status Tracking:**
+- Sprint Progress: 4/4 tasks completed.
+- Issues: None.
+
+**Deliverables (This Turn):**
+- Diff for `pyproject.toml` (add pydantic) in `src-dev/007_roberta-vieira_code.diff`. (Note: this ID is shared for pyproject and diario.py change)
+- Diff for `src/models/diario.py` (Diario to Pydantic model) in `src-dev/007_roberta-vieira_code.diff`.
+- Diff for `src/extractor.py` (Pydantic integration, prompt update) in `src-dev/008_roberta-vieira_code.diff`.
+- New doc `docs/guides/pydantic_best_practices.md` (diff in `src-dev/009_roberta-vieira_code.diff`).
+- Research notes on LLM provider added to scratchpad.
+
+**Scratchpad/Notes:** Added research notes for Task 4.
