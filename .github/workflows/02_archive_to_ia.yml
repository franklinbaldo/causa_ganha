name: 02 - Archive PDF to Internet Archive

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    - cron: '15 3 * * *' # Runs daily at 3:15 AM UTC

env:
  IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
  IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
  # Set a default database path if needed by the script,
  # or rely on the script's default.
  # DB_PATH: data/causaganha.duckdb

jobs:
  archive_pdf_to_ia:
    runs-on: ubuntu-latest
    permissions:
      contents: read # Allow workflow to checkout the repository
      # No other permissions typically needed unless writing back to repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12' # Match the version used in other workflows/project

      - name: Install uv (Python package installer)
        uses: astral-sh/setup-uv@v1 # Using v1 as it's the latest stable version
        with:
          version: "latest" # Or pin to a specific version like "0.1.18"

      - name: Install dependencies
        run: uv sync --dev
        # --system-site-packages can sometimes help with pre-built wheels for speed,
        # but ensure it doesn't conflict with specific needs.
        # If issues, remove it.

      - name: Run Archival Script
        run: |
          echo "Attempting to archive yesterday's TJRO PDF to Internet Archive..."
          # The script pipeline/collect_and_archive.py defaults to fetching yesterday's PDF
          # if no --date or --latest is specified, which is suitable for this cron job.
          uv run python scripts/collect_and_archive.py
        # To specify a date for testing or specific runs via manual dispatch,
        # you could potentially pass inputs, but for cron, the default behavior is good.
        # Example for manual dispatch with date:
        # if: github.event_name == 'workflow_dispatch'
        # run: uv run python pipeline/collect_and_archive.py --date ${{ github.event.inputs.date_to_archive }}

      - name: Upload run artifacts (e.g., logs, if any specific ones are generated)
        if: always() # Run this step even if previous steps fail, to capture logs
        uses: actions/upload-artifact@v4
        with:
          name: archive-run-logs-${{ github.run_id }}
          path: |
            *.log # Example: if your script generates .log files
            # Add specific log paths if your script creates them in known locations
          if-no-files-found: ignore # Don't fail if no log files are found (optional)
